{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Heart_Disease_classification_Data_Analysis (2).ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhuC_4G-uitv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as pt\n",
        "train_df=pd.read_csv(\"heart.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knHerVhDuit6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "c9996287-a81b-4d8f-adf5-ce5d043fe6d9"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>212</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>203</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>294</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "0   52    1   0       125   212    0  ...      0      1.0      2   2     3       0\n",
              "1   53    1   0       140   203    1  ...      1      3.1      0   0     3       0\n",
              "2   70    1   0       145   174    0  ...      1      2.6      0   0     3       0\n",
              "3   61    1   0       148   203    0  ...      0      0.0      2   1     3       0\n",
              "4   62    0   0       138   294    1  ...      0      1.9      1   3     2       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E38ad5-uit8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "85231ee8-1c1b-44ae-de1e-0994a0d27f4f"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>212</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>203</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>294</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020</th>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>221</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>164</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>141</td>\n",
              "      <td>1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1022</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>275</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>118</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1025 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  sex  cp  trestbps  chol  ...  oldpeak  slope  ca  thal  target\n",
              "0      52    1   0       125   212  ...      1.0      2   2     3       0\n",
              "1      53    1   0       140   203  ...      3.1      0   0     3       0\n",
              "2      70    1   0       145   174  ...      2.6      0   0     3       0\n",
              "3      61    1   0       148   203  ...      0.0      2   1     3       0\n",
              "4      62    0   0       138   294  ...      1.9      1   3     2       0\n",
              "...   ...  ...  ..       ...   ...  ...      ...    ...  ..   ...     ...\n",
              "1020   59    1   1       140   221  ...      0.0      2   0     2       1\n",
              "1021   60    1   0       125   258  ...      2.8      1   1     3       0\n",
              "1022   47    1   0       110   275  ...      1.0      1   1     2       0\n",
              "1023   50    0   0       110   254  ...      0.0      2   0     2       1\n",
              "1024   54    1   0       120   188  ...      1.4      1   1     3       0\n",
              "\n",
              "[1025 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEcqkB4Huit8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cdb6a8d-ba11-4e14-a4eb-ea2496a6d76d"
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1025 entries, 0 to 1024\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       1025 non-null   int64  \n",
            " 1   sex       1025 non-null   int64  \n",
            " 2   cp        1025 non-null   int64  \n",
            " 3   trestbps  1025 non-null   int64  \n",
            " 4   chol      1025 non-null   int64  \n",
            " 5   fbs       1025 non-null   int64  \n",
            " 6   restecg   1025 non-null   int64  \n",
            " 7   thalach   1025 non-null   int64  \n",
            " 8   exang     1025 non-null   int64  \n",
            " 9   oldpeak   1025 non-null   float64\n",
            " 10  slope     1025 non-null   int64  \n",
            " 11  ca        1025 non-null   int64  \n",
            " 12  thal      1025 non-null   int64  \n",
            " 13  target    1025 non-null   int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 112.2 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyf0S6Nfuit9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab60df79-683f-447a-a0b8-f7f2c335d54d"
      },
      "source": [
        "train_df.isna().any()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         False\n",
              "sex         False\n",
              "cp          False\n",
              "trestbps    False\n",
              "chol        False\n",
              "fbs         False\n",
              "restecg     False\n",
              "thalach     False\n",
              "exang       False\n",
              "oldpeak     False\n",
              "slope       False\n",
              "ca          False\n",
              "thal        False\n",
              "target      False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FyutPSHuit9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "20604821-fa43-4d4b-d0d9-b58b9e9889e9"
      },
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1025.000000</td>\n",
              "      <td>1025.000000</td>\n",
              "      <td>1025.000000</td>\n",
              "      <td>1025.000000</td>\n",
              "      <td>1025.00000</td>\n",
              "      <td>1025.000000</td>\n",
              "      <td>1025.000000</td>\n",
              "      <td>1025.000000</td>\n",
              "      <td>1025.000000</td>\n",
              "      <td>1025.000000</td>\n",
              "      <td>1025.000000</td>\n",
              "      <td>1025.000000</td>\n",
              "      <td>1025.000000</td>\n",
              "      <td>1025.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>54.434146</td>\n",
              "      <td>0.695610</td>\n",
              "      <td>0.942439</td>\n",
              "      <td>131.611707</td>\n",
              "      <td>246.00000</td>\n",
              "      <td>0.149268</td>\n",
              "      <td>0.529756</td>\n",
              "      <td>149.114146</td>\n",
              "      <td>0.336585</td>\n",
              "      <td>1.071512</td>\n",
              "      <td>1.385366</td>\n",
              "      <td>0.754146</td>\n",
              "      <td>2.323902</td>\n",
              "      <td>0.513171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.072290</td>\n",
              "      <td>0.460373</td>\n",
              "      <td>1.029641</td>\n",
              "      <td>17.516718</td>\n",
              "      <td>51.59251</td>\n",
              "      <td>0.356527</td>\n",
              "      <td>0.527878</td>\n",
              "      <td>23.005724</td>\n",
              "      <td>0.472772</td>\n",
              "      <td>1.175053</td>\n",
              "      <td>0.617755</td>\n",
              "      <td>1.030798</td>\n",
              "      <td>0.620660</td>\n",
              "      <td>0.500070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>126.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>211.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>56.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>240.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>275.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>564.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               age          sex  ...         thal       target\n",
              "count  1025.000000  1025.000000  ...  1025.000000  1025.000000\n",
              "mean     54.434146     0.695610  ...     2.323902     0.513171\n",
              "std       9.072290     0.460373  ...     0.620660     0.500070\n",
              "min      29.000000     0.000000  ...     0.000000     0.000000\n",
              "25%      48.000000     0.000000  ...     2.000000     0.000000\n",
              "50%      56.000000     1.000000  ...     2.000000     1.000000\n",
              "75%      61.000000     1.000000  ...     3.000000     1.000000\n",
              "max      77.000000     1.000000  ...     3.000000     1.000000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzS7LTSOuit-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2f7071d-af11-4715-f3be-3e856bfcefbc"
      },
      "source": [
        "out_l = 0\n",
        "std_o = 3\n",
        "for i, j in enumerate(train_df.columns):\n",
        "    if train_df.std()[i] > 0:\n",
        "        score = (i - train_df.mean()[i]) / train_df.std()[i]  \n",
        "        if np.abs(score) > std_o:\n",
        "            out_l = out_l + 1\n",
        "print(out_l)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef2PkDHIuit-"
      },
      "source": [
        "repl_nan = train_df.mask(train_df.sub(train_df.mean()).div(train_df.std()).abs().gt(3))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5gAb3GTuit-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "d0500741-5eab-431c-bb82-e6a849b6aca1"
      },
      "source": [
        "repl_nan"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>125.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>161.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>106.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020</th>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>140.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>164.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>258.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1022</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>275.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>113.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1025 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  sex  cp  trestbps   chol  ...  oldpeak  slope   ca  thal  target\n",
              "0      52    1   0     125.0  212.0  ...      1.0      2  2.0   3.0       0\n",
              "1      53    1   0     140.0  203.0  ...      3.1      0  0.0   3.0       0\n",
              "2      70    1   0     145.0  174.0  ...      2.6      0  0.0   3.0       0\n",
              "3      61    1   0     148.0  203.0  ...      0.0      2  1.0   3.0       0\n",
              "4      62    0   0     138.0  294.0  ...      1.9      1  3.0   2.0       0\n",
              "...   ...  ...  ..       ...    ...  ...      ...    ...  ...   ...     ...\n",
              "1020   59    1   1     140.0  221.0  ...      0.0      2  0.0   2.0       1\n",
              "1021   60    1   0     125.0  258.0  ...      2.8      1  1.0   3.0       0\n",
              "1022   47    1   0     110.0  275.0  ...      1.0      1  1.0   2.0       0\n",
              "1023   50    0   0     110.0  254.0  ...      0.0      2  0.0   2.0       1\n",
              "1024   54    1   0     120.0  188.0  ...      1.4      1  1.0   3.0       0\n",
              "\n",
              "[1025 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SBAbarduit_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca06c749-a3b9-4941-c55b-01b4053a1e97"
      },
      "source": [
        "repl_nan.isnull().sum().sum() "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YzHlrEJuit_"
      },
      "source": [
        "repl_med = repl_nan.fillna(repl_nan.median())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HiQRQW1uiuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7688f778-7b33-45e7-9925-c04d80694d3a"
      },
      "source": [
        "repl_med.isnull().sum().sum()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUjl_JlJuiuA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "855f58c8-b340-4605-f941-829cb8bbefe7"
      },
      "source": [
        "train_df[['fbs', 'target']].groupby(['fbs']).mean()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fbs</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.521789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.464052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       target\n",
              "fbs          \n",
              "0    0.521789\n",
              "1    0.464052"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzTS9pGZuiuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "445ac401-10a8-470f-e6c4-3ad85a72d339"
      },
      "source": [
        "train_df.slope.value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    482\n",
              "2    469\n",
              "0     74\n",
              "Name: slope, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNOwF9c0uiuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b81d72-6f91-47d0-8246-978d46aa5a4f"
      },
      "source": [
        "train_df.thal.value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    544\n",
              "3    410\n",
              "1     64\n",
              "0      7\n",
              "Name: thal, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMIclT6LuiuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56bded7-cc71-49f5-89b2-1b6c54ea584c"
      },
      "source": [
        "train_df.ca.value_counts()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    578\n",
              "1    226\n",
              "2    134\n",
              "3     69\n",
              "4     18\n",
              "Name: ca, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBsTtzBvuiuB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "e286321b-fec3-4df0-bd63-81b7abf717ea"
      },
      "source": [
        "pd.crosstab(train_df.slope,train_df.target).plot(kind=\"bar\",figsize=(15,6),color=['#DAF7A6','#FF5733' ])\n",
        "pt.title('Heart Disease Frequency for Slope')\n",
        "pt.xlabel('The Slope of The Peak Exercise ST Segment ')\n",
        "pt.ylabel('Frequency')\n",
        "pt.xticks(rotation = 0)\n",
        "pt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAGDCAYAAACSkwm+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debhdZX33//cHEo0IgkCgmESCgCKDTAHhQa1DLUJlsBWFxwnhZ6hiq31qW7X9Vdvir/RyqtYRigrK4IAVHqQqKpU6AUHDLAUESiJCBBkic/j+/tj3oZvjSdjJOTs7WXm/rutcZ697rXWv71p7X4d8uO+1dqoKSZIkSVK3rDfqAiRJkiRJU8+wJ0mSJEkdZNiTJEmSpA4y7EmSJElSBxn2JEmSJKmDDHuSJEmS1EGGPUnS0CR5epKlSdYfdS0aTJJXJLm5vW+7D/lYL0yyaJjHkKR1mWFPktYCSW5M8nvj2o5M8v0hHrOSbLeC9UcmWdZCwdIkNyT5bJJnjm1TVf9dVRtW1bJh1TlV2jW+r+98liZ52qjrGoEPAG9t79tPJ9tZkp2SfCvJHUnuTHJJkgOnoE5J0uMw7EmSHiPJtJXY/EdVtSGwMfB7wH3AJUl2Hkpxw3dQCzljP7/oX7mS12ZttTVw5arsuJwR3P8LnAf8DrAF8KfA3atcnSRpYIY9SeqIJE9LcmaSJW2U7U/71u2d5EdtZOWWJB9L8oS+9ZXk2CTXAtcmuaCturSNcL16RceuqmVVdX1VvQX4HvDe1u/c1ve0tnxkkp8nuafV+Jq+Go5KcnWSXyf5ZpKt+9Z9pE0tvLuNDD1/3LktaOtuTfKhvnX7JPlhO+9Lk7xwFa7rY65Na3t5koWt3x8meU7f9rsn+Uk7xy8mOSPJcX3n//0J+t+uvX5ikg8k+e92Lp9K8qS27oVJFiX58yS3tffxjX39PCnJB5PclOSuJN9vbV9P8ifjjnlZkleMa3tikqXA+vTe9+tb+7OT/Ec71yuTHNy3z+eSfDLJuUl+A7xoXJ+bA9sAJ1bVg+3nB1U14Yj0AMf6VJLz2rX93rjPyA5t3R1JrknyquW/q5K0bjDsSVIHJFmP3gjKpcAs4CXA25Ps3zZZBvwZsDmwb1v/lnHdHAo8F9ixql7Q2nZtI1xfXIlyvgo8f3xjkicDHwUOqKqNgP8FLGzrDgHeDfwhMBP4T+D0vt0vBnYDNgVOA76cZEZb9xHgI1X1FGBb4Eutz1nA14Hj2n7vAM5MMnMlzmXMo9cmvfvYPgMcA2wGfBo4u4WlJwBfAz7fjvll4I9W4jjHA89s57odvffyb/vW/w69UdRZwNHAx5M8ta37ALAnveu6KfCXwCPAycBrxzpIsmvb/+v9B66qB9ooLfTe922TTKf3ufoWvVG5PwFOTfKsvl3/N/A+YCNgfIi7HbgO+EKSQ5NsubwTH/BYrwH+gd7neCFwatv3yfRGD09r+x4OfCLJjss7niStCwx7krT2+Fob8bgzyZ3AJ/rW7QXMrKq/b6MnPwdOpPePXqrqkqr6cVU9XFU30gsovzuu/3+sqjuq6r5J1vkLemFjIo8AOyd5UlXdUlVj0wX/uB3/6qp6GPj/gN3GRm6q6gtVdXur/4PAE4GxEPAQsF2SzatqaVX9uLW/Fji3qs6tqkeq6jxgAbCi+8X6r/HX+tr7r8184NNVdWEb0TwZeADYp/1MB/65qh6qqq/QC6qPK0la33/WjnVPuw6H9232EPD3re9zgaXAs1rYPwp4W1UtbnX9sKoeAM4Gnplk+9bH64AvVtWDA5S1D7AhcHz7XH0XOAc4om+bs9po3SNVdX//zlVV9Eb7bgQ+CNyS5IK+Wlb2WF+vqgvaef01sG+SOcDLgRur6rPtM/JT4EzgsAHOUZI6y7AnSWuPQ6tqk7EfHjsytzXwtHFh8N3AlgBJnpnknCS/THI3vRCx+bj+b56iOmcBd4xvrKrfAK+mF+xuadMLd+ir/yN9td8BpPVFknekN8XzrrZ+4776j6Y3GvazJBcneXlfn4eNuybPA7ZaQe391/jQvvb+a7M18Ofj+p0DPK39LG4hZ8xNKzhev5nABvTueRzr9xutfcztLQyPuZdeQNocmAFcP77TFsC+CLy2hcIj6I08DuJpwM1V9ci485nVt7zCz01VLaqqt1bVtvSu3W+AUyZ7rKpaSu9z8rTW73PHvSevoTcSKknrLMOeJHXDzcAN/WGwqjaqqrFRrE8CPwO2b9Md300vTPUrpsYr6E3D/C1V9c2qeim9wPUzeqOPY/UfM67+J1XVD9O7P+8vgVcBT21B966x+qvq2qo6gt70vX8CvtKm9d0MfH5cn0+uquNX4Zz6r83NwPvG9btBVZ0O3ALMaqN0Y57e9/o39AIdAEn6w8iv6D3gZqe+fjfum1q5Ir8C7qc3jXUiJ9MLPy8B7q2qHw3QJ/RGaee0kDjm6cDivuWBPzdVdTPwcWCiB/gMcqw5Yy+SbEhvBPkX9N6T7417TzasqjcPWpskdZFhT5K64SLgniR/1R7KsX6SnZPs1dZvRO8JiEvbaNog/wi+FXjGIAdvx9smyb8ALwT+boJttkxySAtiD9Cbgjg2ivMp4F1JdmrbbpxkbAreRsDDwBJgWpK/BZ7S1+9rk8xsI0J3tuZHgC8AByXZv9U3I72HnMwe5JxW4ETgj5M8Nz1PTvIHSTYCftRq/dMk05P8IbB3376XAjsl2a3dc/jesRWt/hOBDyfZop3brL77Lper7fsZ4EPpPahn/ST7JnliW/+jdk0+yOCjegAX0hs9/Mt2Pi8EDgLOGGTnJE9N8ndJtkuyXnoPbDkK+PEEmw9yrAOTPK/dG/kPwI9bgDyH3lTV17V9pyfZK8mzV+JcJalzDHuS1AHV+x67l9N7sMcN9EZ6/pXedEfoPZzkfwP30AsUgzxw5b3AyW1a3PKebLhvek9wvBv4D3ohbK+qunyCbdcD/g+9kZg76N0z+OZW/7/RG5U7o00zvQI4oO33TXrTGf+L3rS++3ns1MGXAVe2Oj4CHF5V97UQMPbglyVtn79gkv/tq6oFwJuAjwG/pvcAkiPbugfpPWTmyHaOr6b3wJqxff8L+Hvg2/Se7Dn+gSZ/1fr7cbsO3+Z/7k18PO8ALqd3j+Ad9K5n/7meAuxCLwQPpJ3PQfTei1/Ru0/09VX1swG7eBCYS+88xt7XB2jXaxWOdRrwHnrntyftwTPt/sbfp3d/4y+AX9I7/ycOeq6S1EV57G0FkiRpKiX5HLCoqv5mxHW8HphfVc8bZR2rak25jpK0NnFkT5KkjkuyAb0H+pww6lokSauPYU+SpA5r9/wtoXcP5mkjLkeStBo5jVOSJEmSOsiRPUmSJEnqIMOeJEmSJHXQtFEXMBmbb755zZ07d9RlSJIkSdJIXHLJJb+qqpkTrVurw97cuXNZsGDBqMuQJEmSpJFIctPy1jmNU5IkSZI6aGhhL8mMJBcluTTJlUn+rrV/LskNSRa2n91ae5J8NMl1SS5LssewapMkSZKkrhvmNM4HgBdX1dIk04HvJ/n3tu4vquor47Y/ANi+/TwX+GT7LUmSJElaSUMLe9X7Ar+lbXF6+1nRl/odApzS9vtxkk2SbFVVtwyrRkmSJEl66KGHWLRoEffff/+oS1muGTNmMHv2bKZPnz7wPkN9QEuS9YFLgO2Aj1fVhUneDLwvyd8C3wHeWVUPALOAm/t2X9TabhnX53xgPsDTn/70YZYvSZIkaR2waNEiNtpoI+bOnUuSUZfzW6qK22+/nUWLFrHNNtsMvN9QH9BSVcuqajdgNrB3kp2BdwE7AHsBmwJ/tZJ9nlBV86pq3syZEz5hVJIkSZIGdv/997PZZputkUEPIAmbbbbZSo88rpancVbVncD5wMuq6pbqeQD4LLB322wxMKdvt9mtTZIkSZKGak0NemNWpb5hPo1zZpJN2usnAS8FfpZkq9YW4FDgirbL2cDr21M59wHu8n49SZIkSaNy55138olPfGLox/na177GVVddNeX9DnNkbyvg/CSXARcD51XVOcCpSS4HLgc2B45r258L/By4DjgReMsQa5MkSZKkFVrZsFdVPPLIIyt9nGGFvWE+jfMyYPcJ2l+8nO0LOHZY9UiSJEnSynjnO9/J9ddfz2677caLXvQiLrvsMn7961/z0EMPcdxxx3HIIYdw4403sv/++/Pc5z6XSy65hHPPPZdTTjmFL3zhC8ycOZM5c+aw55578o53vIPrr7+eY489liVLlrDBBhtw4okncscdd3D22Wfzve99j+OOO44zzzyTbbfddkrqH+rTOCVJkiRpbXX88cdzxRVXsHDhQh5++GHuvfdenvKUp/CrX/2KffbZh4MPPhiAa6+9lpNPPpl99tmHiy++mDPPPJNLL72Uhx56iD322IM999wTgPnz5/OpT32K7bffngsvvJC3vOUtfPe73+Xggw/m5S9/Oa985SuntH7DniRJkiQ9jqri3e9+NxdccAHrrbceixcv5tZbbwVg6623Zp999gHgBz/4AYcccggzZsxgxowZHHTQQQAsXbqUH/7whxx22GGP9vnAAw8MtWbDniRJkiQ9jlNPPZUlS5ZwySWXMH36dObOnfvoVyE8+clPftz9H3nkETbZZBMWLlw47FIfZdiTJEmS1jSHzxt1BWueMxas9kNutNFG3HPPPQDcddddbLHFFkyfPp3zzz+fm266acJ99ttvP4455hje9a538fDDD3POOecwf/58nvKUp7DNNtvw5S9/mcMOO4yq4rLLLmPXXXd9zHGm0mr5nj1JkiRJWttsttlm7Lfffuy8884sXLiQBQsWsMsuu3DKKaewww47TLjPXnvtxcEHH8xznvMcDjjgAHbZZRc23nhjoDc6eNJJJ7Hrrruy0047cdZZZwFw+OGH8/73v5/dd9+d66+/fsrqT+8hmGunefPm1YIFqz/hS5IkSUPlyN5vG+LI3tVXX82zn/3sKetv6dKlbLjhhtx777284AUv4IQTTmCPPfaYdL8T1Znkkqqa8APjNE5JkiRJmkLz58/nqquu4v777+cNb3jDlAS9VWHYkyRJkqQpdNppp426BMB79iRJkiSpkwx7kiRJktRBhj1JkiRJ6iDDniRJkiR1kGFPkiRJkkbsG9/4Bs961rPYbrvtOP7446ekT5/GKUmSJEl9rr3/9Cntb/sZR6xw/bJlyzj22GM577zzmD179qNfzL7jjjtO6riO7EmSJEnSCF100UVst912POMZz+AJT3gChx9+OGedddak+zXsSZIkSdIILV68mDlz5jy6PHv2bBYvXjzpfg17kiRJktRBhj1JkiRJGqFZs2Zx8803P7q8aNEiZs2aNel+fUCLJGkgU32zelc83k33kiQ9nr322otrr72WG264gVmzZnHGGWdw2mmnTbpfw54kSZIkjdC0adP42Mc+xv7778+yZcs46qij2GmnnSbf7xTUJkmSJEmdMYpZGwceeCAHHnjglPbpPXuSJEmS1EGGPUmSJEnqIMOeJEmSJHWQYU+SJEmSOsiwJ0mSJEkdZNiTJEmSpA4y7EmSJEnSiB111FFsscUW7LzzzlPWp9+zJ0mSJEn9Dp83tf2dseBxNznyyCN561vfyutf//opO6wje5IkSZI0Yi94wQvYdNNNp7RPw54kSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSdKIHXHEEey7775cc801zJ49m5NOOmnSffrVC5IkSZLUb4CvSphqp59++pT3ObSRvSQzklyU5NIkVyb5u9a+TZILk1yX5ItJntDan9iWr2vr5w6rNkmSJEnqumFO43wAeHFV7QrsBrwsyT7APwEfrqrtgF8DR7ftjwZ+3do/3LaTJEmSJK2CoYW96lnaFqe3nwJeDHyltZ8MHNpeH9KWaetfkiTDqk+SJEmSumyoD2hJsn6ShcBtwHnA9cCdVfVw22QRMKu9ngXcDNDW3wVsNsz6JEmSJAmgqkZdwgqtSn1DDXtVtayqdgNmA3sDO0y2zyTzkyxIsmDJkiWTrlGSJEnSum3GjBncfvvta2zgqypuv/12ZsyYsVL7rZancVbVnUnOB/YFNkkyrY3ezQYWt80WA3OARUmmARsDt0/Q1wnACQDz5s1bM98NSZIkSWuN2bNns2jRItbkwaQZM2Ywe/bsldpnaGEvyUzgoRb0ngS8lN5DV84HXgmcAbwBOKvtcnZb/lFb/91aU6O1JEmSpM6YPn0622yzzajLmHLDHNnbCjg5yfr0pot+qarOSXIVcEaS44CfAmPfFngS8Pkk1wF3AIcPsTZJkiRJ6rShhb2qugzYfYL2n9O7f298+/3AYcOqR5IkSZLWJUN9QIskSZIkaTQMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYMMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYMMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYMMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYMMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6aGhhL8mcJOcnuSrJlUne1trfm2RxkoXt58C+fd6V5Lok1yTZf1i1SZIkSVLXTRti3w8Df15VP0myEXBJkvPaug9X1Qf6N06yI3A4sBPwNODbSZ5ZVcuGWKMkSZIkddLQRvaq6paq+kl7fQ9wNTBrBbscApxRVQ9U1Q3AdcDew6pPkiRJkrpstdyzl2QusDtwYWt6a5LLknwmyVNb2yzg5r7dFjFBOEwyP8mCJAuWLFkyxKolSZIkae019LCXZEPgTODtVXU38ElgW2A34BbggyvTX1WdUFXzqmrezJkzp7xeSZIkSeqCoYa9JNPpBb1Tq+qrAFV1a1Utq6pHgBP5n6mai4E5fbvPbm2SJEmSpJU0zKdxBjgJuLqqPtTXvlXfZq8ArmivzwYOT/LEJNsA2wMXDas+SZIkSeqyYT6Ncz/gdcDlSRa2tncDRyTZDSjgRuAYgKq6MsmXgKvoPcnzWJ/EKUmSJEmrZmhhr6q+D2SCVeeuYJ/3Ae8bVk2SJEmStK5YLU/jlCRJkiStXoY9SZIkSeogw54kSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYMMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYMMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYMMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYMMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6aKCwl2SXYRciSZIkSZo6g47sfSLJRUnekmTjQXZIMifJ+UmuSnJlkre19k2TnJfk2vb7qa09ST6a5LoklyXZYxXPSZIkSZLWeQOFvap6PvAaYA5wSZLTkrz0cXZ7GPjzqtoR2Ac4NsmOwDuB71TV9sB32jLAAcD27Wc+8MmVPRlJkiRJUs/A9+xV1bXA3wB/Bfwu8NEkP0vyh8vZ/paq+kl7fQ9wNTALOAQ4uW12MnBoe30IcEr1/BjYJMlWq3BOkiRJkrTOG/Seveck+TC9wPZi4KCqenZ7/eEB9p8L7A5cCGxZVbe0Vb8EtmyvZwE39+22qLWN72t+kgVJFixZsmSQ8iVJkiRpnTPoyN6/AD8Bdq2qY/tG7H5Bb7RvuZJsCJwJvL2q7u5fV1UF1MoUXFUnVNW8qpo3c+bMldlVkiRJktYZ0wbc7g+A+6pqGUCS9YAZVXVvVX1+eTslmU4v6J1aVV9tzbcm2aqqbmnTNG9r7Yvp3RM4ZnZrkyRJkiStpEFH9r4NPKlveYPWtlxJApwEXF1VH+pbdTbwhvb6DcBZfe2vb0/l3Ae4q2+6pyRJkiRpJQw6sjejqpaOLVTV0iQbPM4++wGvAy5PsrC1vRs4HvhSkqOBm4BXtXXnAgcC1wH3Am8csDZJkiRJ0jiDhr3fJNlj7F69JHsC961oh6r6PpDlrH7JBNsXcOyA9UiSJEmSVmDQsPd24MtJfkEvwP0O8OqhVSVJkiRJmpSBwl5VXZxkB+BZremaqnpoeGVJkiRJkiZj0JE9gL2AuW2fPZJQVacMpSpJkiRJ0qQMFPaSfB7YFlgILGvNBRj2JEmSJGkNNOjI3jxgx/YQFUmSJEnSGm7Q79m7gt5DWSRJkiRJa4FBR/Y2B65KchHwwFhjVR08lKokSZIkSZMyaNh77zCLkCRJkiRNrUG/euF7SbYGtq+qbyfZAFh/uKVJkiRJklbVQPfsJXkT8BXg061pFvC1YRUlSZIkSZqcQR/QciywH3A3QFVdC2wxrKIkSZIkSZMzaNh7oKoeHFtIMo3e9+xJkiRJktZAg4a97yV5N/CkJC8Fvgz83+GVJUmSJEmajEHD3juBJcDlwDHAucDfDKsoSZIkSdLkDPo0zkeAE9uPJEmSJGkNN1DYS3IDE9yjV1XPmPKKJEmSJEmTNuiXqs/rez0DOAzYdOrLkSRJkiRNhYHu2auq2/t+FlfVPwN/MOTaJEmSJEmraNBpnHv0La5Hb6Rv0FFBSZIkSdJqNmhg+2Df64eBG4FXTXk1kiRJkqQpMejTOF807EIkSZIkSVNn0Gmc/2dF66vqQ1NTjiRJkiRpKqzM0zj3As5uywcBFwHXDqMoSZIkSdLkDBr2ZgN7VNU9AEneC3y9ql47rMIkSZIkSatuoK9eALYEHuxbfrC1SZIkSZLWQIOO7J0CXJTk39ryocDJwylJkiRJkjRZgz6N831J/h14fmt6Y1X9dHhlSZIkSZImY9BpnAAbAHdX1UeARUm2GVJNkiRJkqRJGijsJXkP8FfAu1rTdOALwypKkiRJkjQ5g47svQI4GPgNQFX9AthoWEVJkiRJkiZn0LD3YFUVUABJnjy8kiRJkiRJkzVo2PtSkk8DmyR5E/Bt4MThlSVJkiRJmozHfRpnkgBfBHYA7gaeBfxtVZ035NokSVrzHT5v1BWsec5YMOoKJEkMEPaqqpKcW1W7AAY8SZIkSVoLDDqN8ydJ9hpqJZIkSZKkKTPQl6oDzwVem+RGek/kDL1Bv+cMqzBJkiRJ0qpb4chekqe3l/sDzwBeDBwEvLz9XtG+n0lyW5Ir+trem2RxkoXt58C+de9Kcl2Sa5Lsv6onJEmSJEl6/JG9rwF7VNVNSc6sqj9aib4/B3wMOGVc+4er6gP9DUl2BA4HdgKeBnw7yTOratlKHE+SJEmS1DzePXvpe/2Mlem4qi4A7hhw80OAM6rqgaq6AbgO2HtljidJkiRJ+h+PF/ZqOa8n461JLmvTPJ/a2mYBN/dts6i1SZIkSZJWweOFvV2T3J3kHuA57fXdSe5JcvcqHO+TwLbAbsAtwAdXtoMk85MsSLJgyZIlq1CCJEmSJHXfCu/Zq6r1p/JgVXXr2OskJwLntMXFwJy+TWe3ton6OAE4AWDevHlTNdooSZIkSZ0y6PfsTYkkW/UtvgIYe1Ln2cDhSZ6YZBtge+Ci1VmbJEmSJHXJoN+zt9KSnA68ENg8ySLgPcALk+xG7/6/G4FjAKrqyiRfAq4CHgaO9UmckiRJkrTqhhb2quqICZpPWsH27wPeN6x6JEmSJGldslqncUqSJEmSVg/DniRJkiR1kGFPkiRJkjrIsCdJkiRJHWTYkyRJkqQOMuxJkiRJUgcZ9iRJkiSpgwx7kiRJktRBhj1JkiRJ6iDDniRJkiR1kGFPkiRJkjrIsCdJkiRJHWTYkyRJkqQOMuxJkiRJUgdNG3UBkiRJWndde//poy5hjbT9qAtQJziyJ0mSJEkdZNiTJEmSpA4y7EmSJElSBxn2JEmSJKmDDHuSJEmS1EGGPUmSJEnqIMOeJEmSJHWQYU+SJEmSOsiwJ0mSJEkdZNiTJEmSpA4y7EmSJElSBxn2JEmSJKmDDHuSJEmS1EGGPUmSJEnqIMOeJEmSJHWQYU+SJEmSOsiwJ0mSJEkdZNiTJEmSpA4y7EmSJElSBxn2JEmSJKmDDHuSJEmS1EGGPUmSJEnqoKGFvSSfSXJbkiv62jZNcl6Sa9vvp7b2JPlokuuSXJZkj2HVJUmSJEnrgmGO7H0OeNm4tncC36mq7YHvtGWAA4Dt28984JNDrEuSJEmSOm9oYa+qLgDuGNd8CHBye30ycGhf+ynV82NgkyRbDas2SZIkSeq61X3P3pZVdUt7/Utgy/Z6FnBz33aLWttvSTI/yYIkC5YsWTK8SiVJkiRpLTayB7RUVQG1CvudUFXzqmrezJkzh1CZJEmSJK39VnfYu3Vsemb7fVtrXwzM6dtudmuTJEmSJK2C1R32zgbe0F6/ATirr/317amc+wB39U33lCRJkiStpGnD6jjJ6cALgc2TLALeAxwPfCnJ0cBNwKva5ucCBwLXAfcCbxxWXZIkSZK0Lhha2KuqI5az6iUTbFvAscOqRZIkSZLWNSN7QIskSZIkaXgMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYMMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYMMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYMMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6yAOMv9kAAAz3SURBVLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYMMe5IkSZLUQYY9SZIkSeogw54kSZIkdZBhT5IkSZI6aNooDprkRuAeYBnwcFXNS7Ip8EVgLnAj8Kqq+vUo6pMkSZKktd0oR/ZeVFW7VdW8tvxO4DtVtT3wnbYsSZIkSVoFa9I0zkOAk9vrk4FDR1iLJEmSJK3VRhX2CvhWkkuSzG9tW1bVLe31L4EtJ9oxyfwkC5IsWLJkyeqoVZIkSZLWOiO5Zw94XlUtTrIFcF6Sn/WvrKpKUhPtWFUnACcAzJs3b8JtJEmSJGldN5KRvapa3H7fBvwbsDdwa5KtANrv20ZRmyRJkiR1wWoPe0menGSjsdfA7wNXAGcDb2ibvQE4a3XXJkmSJEldMYppnFsC/5Zk7PinVdU3klwMfCnJ0cBNwKtGUFsnXHv/6aMuYY20/YwjRl2CJEmStNqs9rBXVT8Hdp2g/XbgJau7HkmSJEnqojXpqxckSZIkSVPEsCdJkiRJHWTYkyRJkqQOMuxJkiRJUgcZ9iRJkiSpgwx7kiRJktRBhj1JkiRJ6iDDniRJkiR1kGFPkiRJkjrIsCdJkiRJHWTYkyRJkqQOMuxJkiRJUgcZ9iRJkiSpgwx7kiRJktRB00ZdgLTaHD5v1BWsec5YMOoKJEmSNCSO7EmSJElSBxn2JEmSJKmDDHuSJEmS1EGGPUmSJEnqIMOeJEmSJHWQYU+SJEmSOsiwJ0mSJEkdZNiTJEmSpA4y7EmSJElSBxn2JEmSJKmDDHuSJEmS1EGGPUmSJEnqIMOeJEmSJHWQYU+SJEmSOsiwJ0mSJEkdZNiTJEmSpA4y7EmSJElSBxn2JEmSJKmDDHuSJEmS1EGGPUmSJEnqIMOeJEmSJHXQGhf2krwsyTVJrkvyzlHXI0mSJElrozUq7CVZH/g4cACwI3BEkh1HW5UkSZIkrX3WqLAH7A1cV1U/r6oHgTOAQ0ZckyRJkiStdda0sDcLuLlveVFrkyRJkiSthGmjLmBlJZkPzG+LS5NcM8p6tFbZHPjVqItYo3wxo65A6gL/tozn3xZpKvi3ZTz/tizP1stbsaaFvcXAnL7l2a3tUVV1AnDC6ixK3ZBkQVXNG3UdkrrFvy2ShsG/LZoKa9o0zouB7ZNsk+QJwOHA2SOuSZIkSZLWOmvUyF5VPZzkrcA3gfWBz1TVlSMuS5IkSZLWOmtU2AOoqnOBc0ddhzrJ6b+ShsG/LZKGwb8tmrRU1ahrkCRJkiRNsTXtnj1JkiRJ0hQw7KnzkrwsyTVJrkvyzlHXI6kbknwmyW1Jrhh1LZK6IcmcJOcnuSrJlUneNuqatHZzGqc6Lcn6wH8BLwUW0Xvi6xFVddVIC5O01kvyAmApcEpV7TzqeiSt/ZJsBWxVVT9JshFwCXCo/27RqnJkT123N3BdVf28qh4EzgAOGXFNkjqgqi4A7hh1HZK6o6puqaqftNf3AFcDs0ZbldZmhj113Szg5r7lRfhHU5IkreGSzAV2By4cbSVamxn2JEmSpDVIkg2BM4G3V9Xdo65Hay/DnrpuMTCnb3l2a5MkSVrjJJlOL+idWlVfHXU9WrsZ9tR1FwPbJ9kmyROAw4GzR1yTJEnSb0kS4CTg6qr60Kjr0drPsKdOq6qHgbcC36R3k/OXqurK0VYlqQuSnA78CHhWkkVJjh51TZLWevsBrwNenGRh+zlw1EVp7eVXL0iSJElSBzmyJ0mSJEkdZNiTJEmSpA4y7EmSJElSBxn2JEmSJKmDDHuSJEmS1EGGPUlaAyTZrO8x279Msri9vjPJVZPod8sk5yS5NMlVSc5t7XOTXDF1Z7BSNT0/yZXt/J7U2pZ3/guTPHMytSY5MsmS1tdVSd60iv18LskrB9jmhr7af7hqVQ9Uz7wkH52Cfo5KcnmSy5JckeSQJB/vu1739Z3PK8ft+6wk/9HWXZ3khMnWM9Xa+/+0UdchSaMwbdQFSJKgqm4HdgNI8l5gaVV9IMlc4JxJdP33wHlV9ZHW93MmV+mUeA3wj1X1hbGG5Z1/W547Bcf8YlW9NckWwJVJzq6qW6eg34n8RVV9Zao6SzKtfWfoY1TVAmDBJPueDfw1sEdV3ZVkQ2BmVZ3V1s8Fzqmq3ZbTxUeBD/dtv8tk6hmSI4ErgF+MuA5JWu0c2ZOkNd/6SU5so2Hf6hsN2zbJN5JckuQ/k+wwwb5bAYvGFqrqsvEbJJmR5LNtdOenSV7U2o9MclYbubk2yXv69nltkovaiM6nk6w/Qb8vaf1dnuQzSZ6Y5P8BXgX8Q5JTV9M1eFRV3QZcD2ydZM8k32v7fjPJVq3PNyW5uI2GnplkgwnO7R/aKN5vnfdEknwkyd+21/snuSDJeiuo4T+S/HOSBcDbkuyV5IetpouSbJTkhUnOadv/bt/o20+TbNTa/6Kdy2VJ/m6C0rYA7gGWtuuztKpuGOScmvGfr8vbcddP8v6+Yx/T2tdL8okkP0tyXpJzx0YLk9yY5B/bOSxIske7Jtcn+eO+a/lb55TeSPXV4z8jre95wKnpG0mWpHWFYU+S1nzbAx+vqp2AO4E/au0nAH9SVXsC7wA+McG+HwdOSnJ+kr/OxNPZjgWqqnYBjgBOTjKjrdu7He85wGHpTR18NvBqYL824rOM3mjdo9r+nwNe3fqdBry5qv4VOJve6Ndj9hniNeiv6xnAM4CbgH8BXtn2/QzwvrbZV6tqr6raFbgaOHpcH+8HZgJvrKplExzm/X3BayzQvgt4dQvSHwXeCKy/ghoAnlBV89o2XwTe1mr6PeC+ccd8B3Bsez+eD9yX5Pfbddub3qjpnkleMG6/S4FbgRta4D9o+VdvQh8Gvpvk35P8WZJNWvvRwF1VtRewF/CmJNsAfwjMBXYEXgfsO66//27n8J/0Pj+vBPYBxkLdis7ptz4jbYR1AfCaqtqtqsZfN0nqNKdxStKa74aqWtheXwLMTW+63f8CvpxkbLsnjt+xqr7ZAs7LgAOAnybZedxmz6MXKKiqnyW5CXhmW3dem2JJkq+2bR8G9gQubsd+EnDbuD6f1er+r7Z8Mr1Q+c8ree5jVvkaNK9O8jzgAeAYemFtZ+C8tu/6wC1t252THAdsAmwIfLOvn/8XuLCq5q+g1t+axllV96Z3r+AFwJ9V1fXtfVheDdALeNC7lrdU1cWtr7sB+s4Z4AfAh1q4/GpVLWrB6PeBn7ZtNqQXiC7oq2tZkpfRC2QvAT6cZM+qeu8Kzq//vD6b5Jv0Pl+HAMck2bUd9zn5n3v8Nm7Hfh7w5ap6BPhlkvPHdXl2+305sGFV3QPck+SBFiSXd07/zQSfkUHOQZK6zLAnSWu+B/peL6MXrtYD7lzBvVSPqqo7gNOA09q0vxfQ+8fwIGqC5QAnV9W7BuxjKkzqGtDu2RtbSO/esiuravzIEvRGlA6tqkuTHAm8sG/dxfRGkzZt13Vl7ALcDoyNrmYFNQD8ZtCOq+r4JF8HDgR+kGT/1v8/VtWnH2ffAi4CLkpyHvBZ4L0rcexf0BuV/Ex6D9LZuR37T6qqPyiT5MDH6W7sfX6Ex77nj9D7N8uE55TevYUTfUYkaZ3mNE5JWgu10Z0bkhwGkJ5dx2+X5MVp95y1+7i2pTcK0u8/adMwkzwTeDpwTVv30iSbtnudDqU3gvQd4JXpPeyEtn7rcX1eQ2/0bbu2/Drge5M55/EGvQbLcQ0wM8m+bd/pSXZq6zYCbkkynXHTU4FvAMcDXx+7L24Q7fr8ObA7cECS5z5ODeNr3SrJXm27jZI85n/WJtm2qi6vqn+iF0h3oDcieVQbASXJrLH3rG+/pyXZo69pN3pTXAc9r5e160SS3wE2Axa3Y7+5b90zkzyZ3ufnj9K7d29LHhukB/G45zSBe+i9p5K0znFkT5LWXq8BPpnkb4DpwBn07sHqtyfwsSQP0/sffP9aVRfnsU+4/ETr53J6UzSPrKoH2jTBi4AzgdnAF9oTIGnH/FaS9YCH6E3RfDQkVNX9Sd5Ib4rlNHoB5FNTefLNINfgt1TVg22K4UeTbEzvv4f/DFxJm6oJLGm/Nxq375db0Ds7yYET3Af2/lbPmOcCJwHvqKpfJDma3ujhXvTuSZuohvG1vhr4lxa676N3316/t7f7AR9p+/97ew+fDfyovZdLgdfy2Cm304EPpHcv5/3tnP+Ywf0+8JEk97flv6iqXyb5V3rTKH+S3sGX0PufBWfSmy56FXAz8BPgrkEPVlXfWs45TXTv5JjPAZ9Kch+wr/ftSVqXpDd7Q5Kkx2pTGOf1T3+UJivJhlW1NMlm9P5nwn5V9ctR1yVJXeTIniRJWp3OaQ9beQLwDwY9SRoeR/YkSZIkqYN8QIskSZIkdZBhT5IkSZI6yLAnSZIkSR1k2JMkSZKkDjLsSZIkSVIHGfYkSZIkqYP+f9jYsFfbK9VEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGkBSVU0uiuC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "13c401ff-d6c7-4adb-c9bd-279dd00566f0"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>212</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>203</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>294</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "0   52    1   0       125   212    0  ...      0      1.0      2   2     3       0\n",
              "1   53    1   0       140   203    1  ...      1      3.1      0   0     3       0\n",
              "2   70    1   0       145   174    0  ...      1      2.6      0   0     3       0\n",
              "3   61    1   0       148   203    0  ...      0      0.0      2   1     3       0\n",
              "4   62    0   0       138   294    1  ...      0      1.9      1   3     2       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0LIjFoKuiuC"
      },
      "source": [
        "categorical=train_df[[\"slope\",\"ca\",\"thal\"]]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3NtxsdTuiuC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "68edc8be-40a4-4cb4-c7c2-0075b93e256b"
      },
      "source": [
        "pt.figure(figsize=(17, 17))\n",
        "for i, column in enumerate(categorical, 1):\n",
        "    pt.subplot(3, 3, i)\n",
        "    train_df[train_df[\"target\"] == 0][column].hist(bins=35, color='yellow', label='Have Heart Disease = NO', alpha=0.6)\n",
        "    train_df[train_df[\"target\"] == 1][column].hist(bins=35, color='blue', label='Have Heart Disease = YES', alpha=0.6)\n",
        "    pt.legend()\n",
        "    pt.xlabel(column)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1224x1224 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7bYvNCXuiuD"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDC1JngDuiuD"
      },
      "source": [
        "target=train_df['target']\n",
        "data = train_df.drop(['target'],axis=1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfoPzn61uiuD"
      },
      "source": [
        "data1=train_df.drop(['fbs', 'chol'], axis=1)\n",
        "target1=train_df['target']\n",
        "data1 = train_df.drop(['target'],axis=1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRF-AY4quiuD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "442706e7-2fb2-4461-a00a-54437ace6633"
      },
      "source": [
        "data1"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>212</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>203</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>294</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020</th>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>221</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>164</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>141</td>\n",
              "      <td>1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1022</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>275</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>118</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1025 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  sex  cp  trestbps  chol  ...  exang  oldpeak  slope  ca  thal\n",
              "0      52    1   0       125   212  ...      0      1.0      2   2     3\n",
              "1      53    1   0       140   203  ...      1      3.1      0   0     3\n",
              "2      70    1   0       145   174  ...      1      2.6      0   0     3\n",
              "3      61    1   0       148   203  ...      0      0.0      2   1     3\n",
              "4      62    0   0       138   294  ...      0      1.9      1   3     2\n",
              "...   ...  ...  ..       ...   ...  ...    ...      ...    ...  ..   ...\n",
              "1020   59    1   1       140   221  ...      1      0.0      2   0     2\n",
              "1021   60    1   0       125   258  ...      1      2.8      1   1     3\n",
              "1022   47    1   0       110   275  ...      1      1.0      1   1     2\n",
              "1023   50    0   0       110   254  ...      0      0.0      2   0     2\n",
              "1024   54    1   0       120   188  ...      0      1.4      1   1     3\n",
              "\n",
              "[1025 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o7cEwsouiuE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyTvTqu2uiuE"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=0)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnjMTv3guiuE"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnAiAoYOuiuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1854e2b4-8e72-479a-857b-46ba074da808"
      },
      "source": [
        "classifierLR=LogisticRegression()\n",
        "classifierLR.fit(x_train,y_train)\n",
        "classifierLR.score(x_test, y_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8701298701298701"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBwXsitiuiuF"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUrdPBE7uiuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c44d8f-3733-4302-f381-69285fe4e135"
      },
      "source": [
        "classifierNB=MultinomialNB()\n",
        "classifierNB.fit(x_train,y_train)\n",
        "classifierNB.score(x_test, y_test)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.775974025974026"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hoiV5NbuiuF"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypQpWO1FuiuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17ea8cd6-330b-4c1d-c78a-280ba09c7a04"
      },
      "source": [
        "gaussian = GaussianNB()\n",
        "gaussian.fit(x_train, y_train)\n",
        "acc_gaussian = round(gaussian.score(x_train,y_train ) * 100, 2)\n",
        "acc_gaussian"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.59"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhGccT-7uiuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3152206e-a27c-4bae-d470-e207142e32a8"
      },
      "source": [
        "acc_test_gaussian = round(gaussian.score(x_test, y_test) * 100, 2)\n",
        "acc_test_gaussian"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84.42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvZe4FHmuiuG"
      },
      "source": [
        "#data1=train_df.drop(['fbs', 'chol'], axis=1)\n",
        "target1=train_df['target']\n",
        "data1 = train_df.drop(['target'],axis=1)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR7JOPtMuiuG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "2df64bff-9bfb-4b86-9e74-3b3530be4ad4"
      },
      "source": [
        "data1"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>212</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>203</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>294</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020</th>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>221</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>164</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>141</td>\n",
              "      <td>1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1022</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>275</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>118</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1025 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  sex  cp  trestbps  chol  ...  exang  oldpeak  slope  ca  thal\n",
              "0      52    1   0       125   212  ...      0      1.0      2   2     3\n",
              "1      53    1   0       140   203  ...      1      3.1      0   0     3\n",
              "2      70    1   0       145   174  ...      1      2.6      0   0     3\n",
              "3      61    1   0       148   203  ...      0      0.0      2   1     3\n",
              "4      62    0   0       138   294  ...      0      1.9      1   3     2\n",
              "...   ...  ...  ..       ...   ...  ...    ...      ...    ...  ..   ...\n",
              "1020   59    1   1       140   221  ...      1      0.0      2   0     2\n",
              "1021   60    1   0       125   258  ...      1      2.8      1   1     3\n",
              "1022   47    1   0       110   275  ...      1      1.0      1   1     2\n",
              "1023   50    0   0       110   254  ...      0      0.0      2   0     2\n",
              "1024   54    1   0       120   188  ...      0      1.4      1   1     3\n",
              "\n",
              "[1025 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O82vgazpuiuH"
      },
      "source": [
        "x=np.array(training_x)\n",
        "y=np.array(training_y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOhA-Cd6uiuH"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, auc\n",
        "from scipy import interp\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vTsWljeuiuH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u03tqn1uiuI"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nMSjzDm4_Na"
      },
      "source": [
        "atr = train_df.drop(['target'],axis=1)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "8JB7U-6bAqGp",
        "outputId": "63862e88-d568-41de-8273-1997630b1a96"
      },
      "source": [
        "atr"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>212</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>203</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>294</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020</th>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>221</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>164</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>141</td>\n",
              "      <td>1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1022</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>275</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>118</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1025 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  sex  cp  trestbps  chol  ...  exang  oldpeak  slope  ca  thal\n",
              "0      52    1   0       125   212  ...      0      1.0      2   2     3\n",
              "1      53    1   0       140   203  ...      1      3.1      0   0     3\n",
              "2      70    1   0       145   174  ...      1      2.6      0   0     3\n",
              "3      61    1   0       148   203  ...      0      0.0      2   1     3\n",
              "4      62    0   0       138   294  ...      0      1.9      1   3     2\n",
              "...   ...  ...  ..       ...   ...  ...    ...      ...    ...  ..   ...\n",
              "1020   59    1   1       140   221  ...      1      0.0      2   0     2\n",
              "1021   60    1   0       125   258  ...      1      2.8      1   1     3\n",
              "1022   47    1   0       110   275  ...      1      1.0      1   1     2\n",
              "1023   50    0   0       110   254  ...      0      0.0      2   0     2\n",
              "1024   54    1   0       120   188  ...      0      1.4      1   1     3\n",
              "\n",
              "[1025 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTjzcU2uAq4I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-1_gmUauiuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a448931-c1b6-465b-f2a5-9d31da9280ac"
      },
      "source": [
        "pre_score = cross_val_score(estimator = GaussianNB(),\n",
        "                            X = atr, \n",
        "                            y = target,\n",
        "                            scoring = 'accuracy',\n",
        "                            cv = 10,\n",
        "                            verbose = 0)\n",
        "\n",
        "print('Naive-Bayes mean score: %5.3f' %np.mean(pre_score))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive-Bayes mean score: 0.821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATMRnlaHuiuI"
      },
      "source": [
        "X = data1.to_numpy()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO4Hk4iIuiuI"
      },
      "source": [
        "y = target1.to_numpy()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU0pwvdGuiuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60e1389-2331-47c1-824f-7616dbc1fda3"
      },
      "source": [
        "X"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[52.,  1.,  0., ...,  2.,  2.,  3.],\n",
              "       [53.,  1.,  0., ...,  0.,  0.,  3.],\n",
              "       [70.,  1.,  0., ...,  0.,  0.,  3.],\n",
              "       ...,\n",
              "       [47.,  1.,  0., ...,  1.,  1.,  2.],\n",
              "       [50.,  0.,  0., ...,  2.,  0.,  2.],\n",
              "       [54.,  1.,  0., ...,  1.,  1.,  3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxV4cMTTuiuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4859edb-48b8-4462-80ad-5f2d055546f9"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1025, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sBErIpFuiuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa0c8a0-59ea-468f-81a9-b86cf767340e"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1025,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qre4wGE-uiuJ"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wALAdR4BuiuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a223dd10-6e10-47bc-cce9-5f3830f9fd07"
      },
      "source": [
        "# example of grid searching key hyperparametres for logistic regression\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "\n",
        "# define models and parameters\n",
        "model = LogisticRegression()\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2','l1','elasticnet']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "# define grid search\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(x_train, y_train)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.842847 using {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.840089 (0.050907) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.841947 (0.048783) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.841484 (0.051632) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 100, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 100, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.840552 (0.051158) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 100, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 100, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
            "0.000000 (0.000000) with: {'C': 100, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
            "0.841015 (0.051404) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.841008 (0.053050) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.840552 (0.049215) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 10, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.841484 (0.051632) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
            "0.000000 (0.000000) with: {'C': 10, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
            "0.840558 (0.047991) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.839619 (0.051082) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.841458 (0.051973) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.842847 (0.052904) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
            "0.000000 (0.000000) with: {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
            "0.833581 (0.052253) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.834950 (0.057461) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.834487 (0.056399) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.833112 (0.055865) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
            "0.000000 (0.000000) with: {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
            "0.801461 (0.056869) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.802413 (0.056232) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.803345 (0.056029) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
            "0.687167 (0.062747) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
            "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
            "0.000000 (0.000000) with: {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J33pWi-QuiuK"
      },
      "source": [
        "preds = grid_search.predict(x_test)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNbCPR35uiuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5336dcd0-3a48-47f8-ada4-aa0282426ed0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "labels=[0,1]\n",
        "cmx=confusion_matrix(y_test, preds)\n",
        "print(confusion_matrix(y_test, preds))\n",
        "print(classification_report(y_test,preds))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[118  27]\n",
            " [ 13 150]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.81      0.86       145\n",
            "           1       0.85      0.92      0.88       163\n",
            "\n",
            "    accuracy                           0.87       308\n",
            "   macro avg       0.87      0.87      0.87       308\n",
            "weighted avg       0.87      0.87      0.87       308\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMASczXFuiuL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ee0a5d7d-e5af-4d29-9921-f9f3bc08bcb6"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cmx)\n",
        "plt.title('Confusion matrix of the classifier')\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + labels)\n",
        "ax.set_yticklabels([''] + labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMmvBslIuiuL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPselD_auiuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51076b7a-34f1-4711-8897-22cb007c3d55"
      },
      "source": [
        "#Plotting the validation curve of training and testing scores for max_features\n",
        "from sklearn.model_selection import validation_curve\n",
        "param_range= c_values\n",
        "train_scores, test_scores = validation_curve(\n",
        "                                LogisticRegression(),\n",
        "                                X = x_train, y = y_train, \n",
        "                                param_name = 'C', \n",
        "                                param_range = param_range,cv = cv)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvTghNfHuiuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530f595d-f41c-472b-afdc-7a8b7ac607e9"
      },
      "source": [
        "LogisticRegression().get_params().keys()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1GVBAFpuiuM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "5085c254-218f-40e2-932c-4a51a283b2df"
      },
      "source": [
        "#Calculate mean and standard deviation for training set\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "\n",
        "#Calculate mean and standard deviation for testing set\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "#Plot mean accuracy scores for training and testing sets\n",
        "plt.plot(param_range, train_mean, label=\"Training score\", color=\"black\")\n",
        "plt.plot(param_range, test_mean, label=\"Test score\", color=\"red\")\n",
        "\n",
        "#Create plot\n",
        "plt.title(\"Logistic Regression: Validation Curve of feature C\")\n",
        "plt.xlabel(\"Value of C\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.tight_layout()\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVpHieVLuiuN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jitHmVz4uiuN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3j0JWxZuiuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb030cd-0d0a-4f87-bbd6-70ff6da14ca2"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=nb_classifier, param_grid=params_NB, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(x_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.827569 using {'var_smoothing': 6.579332246575683e-05}\n",
            "0.643401 (0.059358) with: {'var_smoothing': 1.0}\n",
            "0.646642 (0.059303) with: {'var_smoothing': 0.8111308307896871}\n",
            "0.652243 (0.059066) with: {'var_smoothing': 0.657933224657568}\n",
            "0.654101 (0.056637) with: {'var_smoothing': 0.533669923120631}\n",
            "0.659677 (0.055199) with: {'var_smoothing': 0.43287612810830584}\n",
            "0.661535 (0.057663) with: {'var_smoothing': 0.3511191734215131}\n",
            "0.666191 (0.057519) with: {'var_smoothing': 0.2848035868435802}\n",
            "0.669001 (0.057667) with: {'var_smoothing': 0.23101297000831597}\n",
            "0.671772 (0.057675) with: {'var_smoothing': 0.1873817422860384}\n",
            "0.672692 (0.056720) with: {'var_smoothing': 0.15199110829529336}\n",
            "0.674570 (0.057142) with: {'var_smoothing': 0.12328467394420659}\n",
            "0.674087 (0.057030) with: {'var_smoothing': 0.1}\n",
            "0.675959 (0.056656) with: {'var_smoothing': 0.08111308307896872}\n",
            "0.679206 (0.057208) with: {'var_smoothing': 0.0657933224657568}\n",
            "0.680125 (0.058130) with: {'var_smoothing': 0.0533669923120631}\n",
            "0.679199 (0.058428) with: {'var_smoothing': 0.04328761281083057}\n",
            "0.677797 (0.059939) with: {'var_smoothing': 0.03511191734215131}\n",
            "0.675939 (0.060727) with: {'var_smoothing': 0.02848035868435802}\n",
            "0.675926 (0.060352) with: {'var_smoothing': 0.02310129700083159}\n",
            "0.675932 (0.060210) with: {'var_smoothing': 0.01873817422860384}\n",
            "0.677341 (0.060797) with: {'var_smoothing': 0.01519911082952933}\n",
            "0.678273 (0.059966) with: {'var_smoothing': 0.012328467394420659}\n",
            "0.677804 (0.059921) with: {'var_smoothing': 0.01}\n",
            "0.677347 (0.060579) with: {'var_smoothing': 0.008111308307896872}\n",
            "0.679669 (0.061954) with: {'var_smoothing': 0.006579332246575682}\n",
            "0.680601 (0.062650) with: {'var_smoothing': 0.005336699231206307}\n",
            "0.679212 (0.061339) with: {'var_smoothing': 0.004328761281083057}\n",
            "0.680614 (0.060039) with: {'var_smoothing': 0.003511191734215131}\n",
            "0.682479 (0.059836) with: {'var_smoothing': 0.002848035868435802}\n",
            "0.691778 (0.059058) with: {'var_smoothing': 0.0023101297000831605}\n",
            "0.702021 (0.058867) with: {'var_smoothing': 0.001873817422860383}\n",
            "0.709429 (0.061951) with: {'var_smoothing': 0.0015199110829529332}\n",
            "0.719640 (0.063281) with: {'var_smoothing': 0.0012328467394420659}\n",
            "0.730353 (0.054899) with: {'var_smoothing': 0.001}\n",
            "0.734064 (0.054157) with: {'var_smoothing': 0.0008111308307896872}\n",
            "0.745703 (0.058351) with: {'var_smoothing': 0.0006579332246575676}\n",
            "0.753176 (0.055640) with: {'var_smoothing': 0.0005336699231206307}\n",
            "0.760629 (0.051556) with: {'var_smoothing': 0.0004328761281083057}\n",
            "0.773644 (0.053028) with: {'var_smoothing': 0.0003511191734215131}\n",
            "0.781090 (0.052301) with: {'var_smoothing': 0.0002848035868435802}\n",
            "0.784814 (0.051210) with: {'var_smoothing': 0.0002310129700083158}\n",
            "0.787611 (0.051063) with: {'var_smoothing': 0.0001873817422860383}\n",
            "0.796890 (0.048413) with: {'var_smoothing': 0.0001519911082952933}\n",
            "0.811770 (0.052193) with: {'var_smoothing': 0.0001232846739442066}\n",
            "0.820605 (0.051407) with: {'var_smoothing': 0.0001}\n",
            "0.825235 (0.049430) with: {'var_smoothing': 8.111308307896872e-05}\n",
            "0.827569 (0.046366) with: {'var_smoothing': 6.579332246575683e-05}\n",
            "0.824778 (0.047791) with: {'var_smoothing': 5.3366992312063123e-05}\n",
            "0.821518 (0.045826) with: {'var_smoothing': 4.328761281083062e-05}\n",
            "0.822437 (0.046098) with: {'var_smoothing': 3.511191734215127e-05}\n",
            "0.825228 (0.047997) with: {'var_smoothing': 2.848035868435799e-05}\n",
            "0.825691 (0.048140) with: {'var_smoothing': 2.310129700083158e-05}\n",
            "0.821987 (0.048760) with: {'var_smoothing': 1.873817422860383e-05}\n",
            "0.819190 (0.048736) with: {'var_smoothing': 1.5199110829529332e-05}\n",
            "0.816875 (0.050165) with: {'var_smoothing': 1.2328467394420658e-05}\n",
            "0.818277 (0.049567) with: {'var_smoothing': 1e-05}\n",
            "0.816882 (0.050125) with: {'var_smoothing': 8.111308307896873e-06}\n",
            "0.815949 (0.049046) with: {'var_smoothing': 6.579332246575683e-06}\n",
            "0.814071 (0.048702) with: {'var_smoothing': 5.336699231206313e-06}\n",
            "0.813609 (0.049378) with: {'var_smoothing': 4.328761281083053e-06}\n",
            "0.813146 (0.050033) with: {'var_smoothing': 3.5111917342151275e-06}\n",
            "0.812207 (0.049421) with: {'var_smoothing': 2.848035868435799e-06}\n",
            "0.811744 (0.050063) with: {'var_smoothing': 2.310129700083158e-06}\n",
            "0.812207 (0.050324) with: {'var_smoothing': 1.873817422860383e-06}\n",
            "0.811744 (0.050191) with: {'var_smoothing': 1.519911082952933e-06}\n",
            "0.811744 (0.050191) with: {'var_smoothing': 1.232846739442066e-06}\n",
            "0.811744 (0.050191) with: {'var_smoothing': 1e-06}\n",
            "0.811744 (0.050191) with: {'var_smoothing': 8.111308307896872e-07}\n",
            "0.811744 (0.050191) with: {'var_smoothing': 6.579332246575682e-07}\n",
            "0.811744 (0.050191) with: {'var_smoothing': 5.336699231206313e-07}\n",
            "0.811274 (0.049810) with: {'var_smoothing': 4.3287612810830526e-07}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 3.5111917342151277e-07}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 2.848035868435799e-07}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 2.310129700083158e-07}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 1.873817422860383e-07}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 1.519911082952933e-07}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 1.232846739442066e-07}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 1e-07}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 8.111308307896873e-08}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 6.579332246575682e-08}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 5.336699231206302e-08}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 4.3287612810830526e-08}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 3.5111917342151277e-08}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 2.848035868435799e-08}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 2.310129700083158e-08}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 1.873817422860383e-08}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 1.519911082952933e-08}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 1.232846739442066e-08}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 1e-08}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 8.111308307896856e-09}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 6.579332246575682e-09}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 5.336699231206302e-09}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 4.328761281083061e-09}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 3.5111917342151273e-09}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 2.848035868435805e-09}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 2.310129700083158e-09}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 1.873817422860387e-09}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 1.519911082952933e-09}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 1.2328467394420635e-09}\n",
            "0.810805 (0.049688) with: {'var_smoothing': 1e-09}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNfWBuG8uiuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daff4d6d-6a73-43f0-c6fc-f50c0a5da363"
      },
      "source": [
        "grid_result.best_params_"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'var_smoothing': 6.579332246575683e-05}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqhFUpSSuiuO"
      },
      "source": [
        "preds = grid_search.predict(x_test)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHPiLe8duiuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b470b64-7e9c-4a08-a3a1-a06ce79c918f"
      },
      "source": [
        "labels=[0,1]\n",
        "cmx_n=confusion_matrix(y_test, preds,labels)\n",
        "print(confusion_matrix(y_test, preds))\n",
        "print(classification_report(y_test,preds))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[113  32]\n",
            " [ 13 150]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.78      0.83       145\n",
            "           1       0.82      0.92      0.87       163\n",
            "\n",
            "    accuracy                           0.85       308\n",
            "   macro avg       0.86      0.85      0.85       308\n",
            "weighted avg       0.86      0.85      0.85       308\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ita-MFdAuiuO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "31af6917-1d99-47fd-b303-e4ec407fffd7"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cmx_n)\n",
        "plt.title('Confusion matrix of the classifier')\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + labels)\n",
        "ax.set_yticklabels([''] + labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnGyVL5fuiuP"
      },
      "source": [
        "#Plotting the validation curve of training and testing scores for max_features\n",
        "from sklearn.model_selection import validation_curve\n",
        "param_range= np.logspace(0,-9, num=100)\n",
        "train_scores, test_scores = validation_curve(\n",
        "                                GaussianNB(),\n",
        "                                X = x_train, y = y_train, \n",
        "                                param_name = 'var_smoothing', \n",
        "                                param_range = np.logspace(0,-9, num=100),cv = cv)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kic4pdM0uiuP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "078f6c90-68b4-4a68-f287-e824756ec0dd"
      },
      "source": [
        "#Calculate mean and standard deviation for training set\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "\n",
        "#Calculate mean and standard deviation for testing set\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "#Plot mean accuracy scores for training and testing sets\n",
        "plt.plot(param_range, train_mean, label=\"Training score\", color=\"black\")\n",
        "plt.plot(param_range, test_mean, label=\"Test score\", color=\"red\")\n",
        "\n",
        "#Create plot\n",
        "plt.title(\"Validation Curve of var_smooting for NAive bayes classifier\")\n",
        "plt.xlabel(\"Value of var_smooting\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.tight_layout()\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoI6TPLRTCln",
        "outputId": "4720239c-9943-41d1-ecd3-f17cd539416b"
      },
      "source": [
        "!pip3 install autokeras"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting autokeras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/12/cf698586ccc8245f08d1843dcafb65b064a2e9e2923b889dc58e1019f099/autokeras-1.0.12-py3-none-any.whl (164kB)\n",
            "\r\u001b[K     |██                              | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 31.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 30kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 40kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 81kB 15.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 92kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 102kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 112kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 122kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 133kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 143kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 153kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 17.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.1.5)\n",
            "Collecting keras-tuner>=1.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from autokeras) (0.22.2.post1)\n",
            "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from autokeras) (2.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from autokeras) (20.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->autokeras) (1.0.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.32.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (2.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.36.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (2.4.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.12.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (2.4.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (3.12.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->autokeras) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (3.0.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.28.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (56.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.3.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.10.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.4.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=652d9d2aee2e69b44a1e3eeb4d2ce2c9bcf634348cbcfca56293ab1aa61407af\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=cb88dd51a5b3477bafe4a51488c7158428a8f511c55034d7867991d74072ddbd\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner, autokeras\n",
            "Successfully installed autokeras-1.0.12 colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKlrZb6WExa9",
        "outputId": "ff4d022e-a46f-4939-b573-c62d8139992c"
      },
      "source": [
        "import autokeras as ak\n",
        "\n",
        "clf = ak.StructuredDataClassifier(overwrite = True, max_trials=250)\n",
        "clf.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=100)\n",
        "results = clf.predict(x_test)\n",
        "print(clf.evaluate(x_test,y_test))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 143 Complete [00h 00m 19s]\n",
            "val_accuracy: 1.0\n",
            "\n",
            "Best val_accuracy So Far: 1.0\n",
            "Total elapsed time: 00h 42m 13s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 14ms/step - loss: 0.6435 - accuracy: 0.6156 - val_loss: 0.5444 - val_accuracy: 0.8247\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5508 - accuracy: 0.8142 - val_loss: 0.4560 - val_accuracy: 0.8539\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.8289 - val_loss: 0.3897 - val_accuracy: 0.8701\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.8358 - val_loss: 0.3494 - val_accuracy: 0.8896\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8575 - val_loss: 0.3257 - val_accuracy: 0.8929\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8603 - val_loss: 0.3101 - val_accuracy: 0.8961\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3505 - accuracy: 0.8676 - val_loss: 0.2984 - val_accuracy: 0.8896\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3337 - accuracy: 0.8651 - val_loss: 0.2888 - val_accuracy: 0.8896\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3191 - accuracy: 0.8629 - val_loss: 0.2801 - val_accuracy: 0.8929\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3059 - accuracy: 0.8647 - val_loss: 0.2726 - val_accuracy: 0.8929\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2939 - accuracy: 0.8672 - val_loss: 0.2650 - val_accuracy: 0.8994\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2823 - accuracy: 0.8741 - val_loss: 0.2572 - val_accuracy: 0.8994\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2711 - accuracy: 0.8849 - val_loss: 0.2495 - val_accuracy: 0.9026\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2606 - accuracy: 0.8954 - val_loss: 0.2422 - val_accuracy: 0.9058\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2507 - accuracy: 0.9133 - val_loss: 0.2351 - val_accuracy: 0.9058\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2413 - accuracy: 0.9187 - val_loss: 0.2281 - val_accuracy: 0.9156\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2325 - accuracy: 0.9215 - val_loss: 0.2217 - val_accuracy: 0.9188\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2245 - accuracy: 0.9260 - val_loss: 0.2154 - val_accuracy: 0.9221\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2166 - accuracy: 0.9256 - val_loss: 0.2091 - val_accuracy: 0.9221\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2092 - accuracy: 0.9268 - val_loss: 0.2029 - val_accuracy: 0.9221\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2017 - accuracy: 0.9284 - val_loss: 0.1968 - val_accuracy: 0.9221\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1948 - accuracy: 0.9340 - val_loss: 0.1908 - val_accuracy: 0.9221\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1878 - accuracy: 0.9340 - val_loss: 0.1849 - val_accuracy: 0.9221\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1810 - accuracy: 0.9387 - val_loss: 0.1792 - val_accuracy: 0.9253\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1746 - accuracy: 0.9447 - val_loss: 0.1735 - val_accuracy: 0.9253\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1683 - accuracy: 0.9447 - val_loss: 0.1680 - val_accuracy: 0.9253\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1622 - accuracy: 0.9447 - val_loss: 0.1623 - val_accuracy: 0.9318\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1560 - accuracy: 0.9504 - val_loss: 0.1570 - val_accuracy: 0.9318\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1500 - accuracy: 0.9514 - val_loss: 0.1516 - val_accuracy: 0.9253\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1444 - accuracy: 0.9516 - val_loss: 0.1464 - val_accuracy: 0.9318\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1386 - accuracy: 0.9544 - val_loss: 0.1413 - val_accuracy: 0.9448\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1333 - accuracy: 0.9569 - val_loss: 0.1362 - val_accuracy: 0.9448\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1280 - accuracy: 0.9689 - val_loss: 0.1311 - val_accuracy: 0.9513\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 0.9725 - val_loss: 0.1266 - val_accuracy: 0.9513\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1176 - accuracy: 0.9739 - val_loss: 0.1216 - val_accuracy: 0.9578\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.9755 - val_loss: 0.1171 - val_accuracy: 0.9708\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.9818 - val_loss: 0.1127 - val_accuracy: 0.9708\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.9818 - val_loss: 0.1086 - val_accuracy: 0.9708\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.9818 - val_loss: 0.1041 - val_accuracy: 0.9708\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0942 - accuracy: 0.9818 - val_loss: 0.1003 - val_accuracy: 0.9708\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0900 - accuracy: 0.9818 - val_loss: 0.0960 - val_accuracy: 0.9708\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9818 - val_loss: 0.0924 - val_accuracy: 0.9708\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9818 - val_loss: 0.0885 - val_accuracy: 0.9708\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9818 - val_loss: 0.0849 - val_accuracy: 0.9708\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9818 - val_loss: 0.0814 - val_accuracy: 0.9773\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0710 - accuracy: 0.9821 - val_loss: 0.0781 - val_accuracy: 0.9773\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0677 - accuracy: 0.9846 - val_loss: 0.0746 - val_accuracy: 0.9870\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 0.9861 - val_loss: 0.0715 - val_accuracy: 0.9903\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.0615 - accuracy: 0.9940 - val_loss: 0.0685 - val_accuracy: 0.9903\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0586 - accuracy: 0.9940 - val_loss: 0.0658 - val_accuracy: 0.9903\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9940 - val_loss: 0.0632 - val_accuracy: 0.9903\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 0.9940 - val_loss: 0.0606 - val_accuracy: 0.9935\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9988 - val_loss: 0.0582 - val_accuracy: 0.9935\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 0.9996 - val_loss: 0.0561 - val_accuracy: 0.9935\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0467 - accuracy: 0.9996 - val_loss: 0.0538 - val_accuracy: 0.9935\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.9996 - val_loss: 0.0515 - val_accuracy: 0.9935\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9996 - val_loss: 0.0497 - val_accuracy: 0.9935\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0406 - accuracy: 0.9996 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9903\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9903\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9903\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9903\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9903\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9903\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9903\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9903\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9903\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9903\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9903\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9903\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9903\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9903\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9903\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9903\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9903\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9903\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9903\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9903\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9903\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9903\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9903\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9903\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9903\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9903\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9903\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9903\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9903\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9903\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9903\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9903\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9903\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9903\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9903\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9903\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9903\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9903\n",
            "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c59c21d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c59c19170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c5a0b57a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c59bbc830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c5969aa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c596b5200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c5969af80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c59689b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c596ae8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c596b5b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c59651050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c596b0050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9903\n",
            "[0.021179882809519768, 0.9902597665786743]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcoYTwOmKoZP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CLJ-ExlUrI7",
        "outputId": "19b2629f-147f-4e1e-d8a9-fb49178f4086"
      },
      "source": [
        "model = clf.export_model()\n",
        "print(model.summary())"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c59ac1440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c59b14200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c5a414dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6cb012fcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c5a414830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c59b148c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c59d1bcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f6c5ceae680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 13)]              0         \n",
            "_________________________________________________________________\n",
            "multi_category_encoding (Mul (None, 13)                0         \n",
            "_________________________________________________________________\n",
            "normalization (Normalization (None, 13)                27        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                448       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "_________________________________________________________________\n",
            "classification_head_1 (Activ (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,564\n",
            "Trainable params: 1,537\n",
            "Non-trainable params: 27\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN_JtbUBX8gX",
        "outputId": "1ae6bbea-1f86-48cf-ea26-8a47f6872a2f"
      },
      "source": [
        "labels=[0,1]\n",
        "cmx_n=confusion_matrix(y_test, results,labels)\n",
        "print(confusion_matrix(y_test, results))\n",
        "print(classification_report(y_test,results))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[145   0]\n",
            " [  3 160]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       145\n",
            "           1       1.00      0.98      0.99       163\n",
            "\n",
            "    accuracy                           0.99       308\n",
            "   macro avg       0.99      0.99      0.99       308\n",
            "weighted avg       0.99      0.99      0.99       308\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}